{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Atividade de Programação 02\n",
    "## Percepção Computacional 2020.2e\n",
    "### Prof. Herman\n",
    "\n",
    "Utilizando a base de dados [\"Free Spoken Digit Dataset (FSDD)\"](https://github.com/Jakobovski/free-spoken-digit-dataset) e como inspiração o modelo de rede neural pré-existente para reconhecimento de dígitos falados disponível no  [github](https://github.com/adhishthite/sound-mnist), implemente um Notebook Python no Google Colab contemplando o seguinte:\n",
    "\n",
    "1.  Reproduzir o experimento de treinamento/classificação de dígitos do código github mencionado acima. (2 pontos)\n",
    "2.   Treinar e testar um classificador que, a partir de um arquivo .wav contendo o som de um dígito qualquer, identificar qual dos 6 voluntários da base de dados pronunciou aquele dígito. Garantir que os conjuntos de treinamento e de teste são disjuntos. Apresentar curvas de treinamento (validação e acurácia nos conjs. de treino  e de validação), o relatório de métricas no conj. de teste e a matriz de confusão. (3 pontos)\n",
    "3.    Treinar e testar um classificador que, a partir de um arquivo .wav contendo o som de um dígito qualquer, identificar qual o sotaque (USA/neutral versus Outros) está presente na pronúncia do dígito. Apresentar os mesmos artefatos do item anterior. (3 pontos)\n",
    "4.    Montar uma pequena amostra de dados com as vozes de pelo menos 2 voluntários da equipe pronunciando os mesmos dígitos da base de dados (3 gravações por dígito por voluntário) e avaliar os classificadores 1. e o 3 sobre esta amostra, focando apenas nos relatórios de classificação. (2 pontos)\n",
    "\n",
    "Cada equipe tem total liberdade para:\n",
    "* definir como irá tratar os dados (eventuais pré-processamentos) \n",
    "* definir quais características (se alguma) serão utilizadas para entrada dos modelos de classificação\n",
    "* modificar o modelo existente ou escolher outro modelo de aprendizagem de máquina para as tarefas acima."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#obtendo código-exemplo e base de dados num único comando \n",
    "!git clone https://github.com/adhishthite/sound-mnist.git"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Base de dados completa\n",
    "!git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports necessários"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo da Rede Neural"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Arquitetura utilizada no treinamento dos modelos das questões 1 e 2, apenas alterando a quantidade de classes na camada de saída.\n",
    "\n",
    "A arquitetura consiste de 3 camadas convolucionais, 1 camada de max pooling, 3 camadas densas e a saída com ativação softmax. São feitas normalizações (batch normalization) após cada camada convolucional e densa, e também dropout pra cada camada densa."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conversão de WAV para MFCC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Método para conversão de arquivos de áudio WAV para Mel-Frequency Cepstrum Coefficient (MFCC), que é uma representação do espectro de potência de um som.\n",
    "\n",
    "O MFCC é utilizado para entrada das redes neurais do notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def wav2mfcc(file_path, max_pad_len=20):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=8000)\n",
    "    pad_width = max_pad_len - mfcc.shape[1]\n",
    "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfcc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Função de teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def check_preds(model, X, y):\n",
    "    predictions = model.predict_classes(X)\n",
    "\n",
    "    print(classification_report(y, to_categorical(predictions)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Função para visualizar gráficos do treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_acc_val_graph(history):\n",
    "  #  \"Accuracy\"\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'validation'], loc='upper left')\n",
    "  plt.show()\n",
    "  # \"Loss\"\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'validation'], loc='upper left')\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Função para plotar a matriz de confusão"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_confusion_matrix(model, X_test, y_test, label):\n",
    "  y_pred = model.predict_classes(X_test)\n",
    "\n",
    "  cm = confusion_matrix(y_test.argmax(axis=1), y_pred)\n",
    "\n",
    "  df_cm = pd.DataFrame(cm, index = label,\n",
    "                    columns = label)\n",
    "  plt.figure(figsize = (10,7))\n",
    "  ax = sn.heatmap(df_cm, annot=True)\n",
    "  ax.set_title('Confusion matrix')\n",
    "  ax.set_ylabel(\"Label verdadeiro\")\n",
    "  ax.set_xlabel(\"Label predito\")\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Questão 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reproduzir o experimento de treinamento/classificação de dígitos do código github mencionado acima. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carregando dados - Train/Test split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Os dados são carregados e convertidos para MFCC, além de armazenar o label do áudio através do nome do arquivo. (ex: **0**_nicolas_1.wav - nicolas falando o digito 0)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_data_digit(recording_path):\n",
    "    labels = []\n",
    "    mfccs = []\n",
    "\n",
    "    for f in os.listdir(recording_path):\n",
    "        if f.endswith('.wav'):\n",
    "            # MFCC\n",
    "            mfccs.append(wav2mfcc(recording_path + f))\n",
    "\n",
    "            # List of labels\n",
    "            label = f.split('_')[0]\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.asarray(mfccs), to_categorical(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adquire os dados, o modelo, e faz a separação em dados de treinamento e teste (90% treinamento e 10% teste)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_all(recording_path):\n",
    "    mfccs, labels = get_data_digit(recording_path)\n",
    "\n",
    "    dim_1 = mfccs.shape[1]\n",
    "    dim_2 = mfccs.shape[2]\n",
    "    channels = 1\n",
    "    classes = 10\n",
    "\n",
    "    X = mfccs\n",
    "    X = X.reshape((mfccs.shape[0], dim_1, dim_2, channels))\n",
    "    y = labels\n",
    "\n",
    "    input_shape = (dim_1, dim_2, channels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "    model = get_cnn_model(input_shape, classes)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Treinamento da rede "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizamos o dataset de 1500 dados do repositório, onde apenas são utilizados os áudios de 3 pessoas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test, digit_classification_model = get_all('./sound-mnist/recordings/')\n",
    "digit_classification_model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Realizando o treinamento com 50 épocas, como é dito no repositório. 10% do conjunto de treinamento é utilizado para validação."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = digit_classification_model.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1, validation_split=0.1)\n",
    "\n",
    "digit_classification_model.save('digit_classification_model.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualização dos gráficos de acurácia e loss da rede"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_acc_val_graph(history)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modelo atingiu uma acurácia de 92,59% no conjunto de validação."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check_preds(digit_classification_model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_classification_model.evaluate(X_test,y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "No conjunto de testes, que possui 150 áudios, foi possível alcançar uma acurácia de aproximadamente 94%."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_confusion_matrix(digit_classification_model, X_test, y_test, [i for i in range(10)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modelo se saiu bem nos dados, tendo confundido duas vezes o número 3 pelo 2 e também duas vezes o número 9 pelo 5."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Treinamento com mais épocas\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "No repositório, é mostrado um gráfico com um treinamento de 1000 épocas. Por isso, também foi realizado o treinamento de um modelo por 1000 épocas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test, digit_classification_model_more_epochs = get_all('./sound-mnist/recordings/')\n",
    "history = digit_classification_model_more_epochs.fit(X_train, y_train, batch_size=64, epochs=1000, verbose=1, validation_split=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gráficos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_acc_val_graph(history)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "No treinamento com 1000 épocas, o modelo atingiu uma acurácia de aproximadamente 93% no conjunto de validação na última época."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check_preds(digit_classification_model_more_epochs, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_classification_model_more_epochs.evaluate(X_test,y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "No conjunto de testes, o modelo conseguiu uma acurácia de 97% em 150 dados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_confusion_matrix(digit_classification_model_more_epochs, X_test, y_test, [i for i in range(10)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Questão 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Treinar e testar um classificador que, a partir de um arquivo .wav contendo o som de um dígito qualquer, identificar qual o sotaque (USA/Neutral versus Outros) está presente na pronúncia do dígito. Apresentar os mesmos artefatos do item anterior."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo da rede alterado para classificação binária"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "No modelo para classificação binária (EUA/NEUTRO ou OUTROS), modificamos a quantidade de classes na saída, o algoritmo de loss e também a função de ativação na camada de saída."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_binary_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carregando dados - Train/Test split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Os labels para esse modelo são feitos através de um mapeamento do nome do arquivo para 0 ou 1, representando se o falante tem o sotaque OUTROS ou EUA/NEUTRO, respectivamente.\n",
    "\n",
    "No dataset, jackson e theo são dos EUA."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_data_accent(recording_path, name_labels):\n",
    "    labels = []\n",
    "    mfccs = []\n",
    "\n",
    "    for f in os.listdir(recording_path):\n",
    "        if f.endswith('.wav'):\n",
    "            # MFCC\n",
    "            mfccs.append(wav2mfcc(recording_path + f))\n",
    "\n",
    "            # List of labels\n",
    "            name = f.split('_')[1]\n",
    "            labels.append(name_labels[name])\n",
    "\n",
    "\n",
    "    return np.asarray(mfccs), np.asarray(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_all(recording_path):\n",
    "    name_labels = {\n",
    "      'jackson': 1,\n",
    "      'nicolas': 0,\n",
    "      'theo': 1,\n",
    "      'yweweler': 0,\n",
    "      'george': 0,\n",
    "      'lucas': 0\n",
    "    }\n",
    "    mfccs, labels = get_data_accent(recording_path, name_labels)\n",
    "\n",
    "    dim_1 = mfccs.shape[1]\n",
    "    dim_2 = mfccs.shape[2]\n",
    "    channels = 1\n",
    "\n",
    "    X = mfccs\n",
    "    X = X.reshape((mfccs.shape[0], dim_1, dim_2, channels))\n",
    "    y = labels\n",
    "\n",
    "    input_shape = (dim_1, dim_2, channels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1, stratify=y)\n",
    "\n",
    "    model = get_binary_cnn_model(input_shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Treinamento da rede"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test, accent_classifier_model = get_all('./free-spoken-digit-dataset/recordings/')\n",
    "accent_classifier_model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = accent_classifier_model.fit(X_train, y_train, validation_split=0.1, batch_size=64, epochs=50, verbose=1)\n",
    "\n",
    "accent_classifier_model.save('accent_classifier_model.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualização dos gráficos de acurácia e loss da rede"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_acc_val_graph(history)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modelo atingiu uma acurácia de 97,04% no conjunto de validação."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modificamos as funções de teste e matriz de confusão para o problema de classificação binária"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def check_preds_binary(model, X, y):\n",
    "    predictions = model.predict_classes(X)\n",
    "\n",
    "    print(classification_report(y, predictions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_confusion_matrix_binary(model, X_test, y_test, label):\n",
    "  y_pred = model.predict_classes(X_test)\n",
    "\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "  df_cm = pd.DataFrame(cm, index = label,\n",
    "                    columns = label)\n",
    "  plt.figure(figsize = (10,7))\n",
    "  ax = sn.heatmap(df_cm, annot=True, fmt='d')\n",
    "  ax.set_title('Confusion matrix')\n",
    "  ax.set_ylabel(\"Label verdadeiro\")\n",
    "  ax.set_xlabel(\"Label predito\")\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check_preds_binary(accent_classifier_model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accent_classifier_model.evaluate(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modelo atingiu uma acurácia de 97,33% no conjunto de testes, que consiste em 300 dados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_confusion_matrix_binary(accent_classifier_model, X_test, y_test, [\"Outros\", \"USA/Neutro\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Questão 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Montar uma pequena amostra de dados com as vozes de pelo menos 2 voluntários da equipe pronunciando os mesmos dígitos da base de dados (3 gravações por dígito por voluntário) e avaliar os classificadores 1. e o 3 sobre esta amostra, focando apenas nos relatórios de classificação.\n",
    "\n",
    "A base de dados consiste de 60 áudios gravados, de 2 alunos, cada um repetindo 3 vezes os digitos.\n",
    "\n",
    "Utilizamos o script disponibilizado no repositório do dataset FSDD para realizar o corte dos audios e um guia para a gravação."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Obtendo base de dados\n",
    "!git clone https://github.com/HenriqueCA/percepcao_dataset.git"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def reshape_data(mfccs, labels):\n",
    "  dim_1 = mfccs.shape[1]\n",
    "  dim_2 = mfccs.shape[2]\n",
    "  channels = 1\n",
    "\n",
    "  X = mfccs\n",
    "  X = X.reshape((mfccs.shape[0], dim_1, dim_2, channels))\n",
    "  y = labels\n",
    "\n",
    "  return X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classificador da Questão 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mfccs, labels = get_data_digit('./percepcao_dataset/recordings/')\n",
    "X, y = reshape_data(mfccs, labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check_preds(digit_classification_model,X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit_classification_model.evaluate(X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modelo conseguiu uma acurácia de 30% considerando o conjunto gravado pelo grupo, contendo 60 áudios."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_confusion_matrix(digit_classification_model, X, y, [i for i in range(10)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classificador da Questão 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mfccs, labels = get_data_accent('./percepcao_dataset/recordings/', {'henrique': 0, 'flavio':0})\n",
    "X, y = reshape_data(mfccs, labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check_preds_binary(accent_classifier_model,X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accent_classifier_model.evaluate(X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modelo conseguiu uma acurácia de aproximadamente 76% considerando o conjunto de testes de 60 dados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_confusion_matrix_binary(accent_classifier_model, X, y, [\"Outros\", \"USA/Neutro\"])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}