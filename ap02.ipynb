{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade de Programação 02\n",
    "## Percepção Computacional 2020.2e\n",
    "### Prof. Herman\n",
    "\n",
    "Utilizando a base de dados [\"Free Spoken Digit Dataset (FSDD)\"](https://github.com/Jakobovski/free-spoken-digit-dataset) e como inspiração o modelo de rede neural pré-existente para reconhecimento de dígitos falados disponível no  [github](https://github.com/adhishthite/sound-mnist), implemente um Notebook Python no Google Colab contemplando o seguinte:\n",
    "\n",
    "1.  Reproduzir o experimento de treinamento/classificação de dígitos do código github mencionado acima. (2 pontos)\n",
    "2.   Treinar e testar um classificador que, a partir de um arquivo .wav contendo o som de um dígito qualquer, identificar qual dos 6 voluntários da base de dados pronunciou aquele dígito. Garantir que os conjuntos de treinamento e de teste são disjuntos. Apresentar curvas de treinamento (validação e acurácia nos conjs. de treino  e de validação), o relatório de métricas no conj. de teste e a matriz de confusão. (3 pontos)\n",
    "3.    Treinar e testar um classificador que, a partir de um arquivo .wav contendo o som de um dígito qualquer, identificar qual o sotaque (USA/neutral versus Outros) está presente na pronúncia do dígito. Apresentar os mesmos artefatos do item anterior. (3 pontos)\n",
    "4.    Montar uma pequena amostra de dados com as vozes de pelo menos 2 voluntários da equipe pronunciando os mesmos dígitos da base de dados (3 gravações por dígito por voluntário) e avaliar os classificadores 1. e o 3 sobre esta amostra, focando apenas nos relatórios de classificação. (2 pontos)\n",
    "\n",
    "Cada equipe tem total liberdade para:\n",
    "* definir como irá tratar os dados (eventuais pré-processamentos) \n",
    "* definir quais características (se alguma) serão utilizadas para entrada dos modelos de classificação\n",
    "* modificar o modelo existente ou escolher outro modelo de aprendizagem de máquina para as tarefas acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtendo código-exemplo e base de dados num único comando \n",
    "!git clone https://github.com/adhishthite/sound-mnist.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base de dados completa\n",
    "!git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo da Rede Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura utilizada no treinamento dos modelos das questões 1 e 2, apenas alterando a quantidade de classes na camada de saída.\n",
    "\n",
    "A arquitetura consiste de 3 camadas convolucionais, 1 camada de max pooling, 3 camadas densas e a saída com ativação softmax. São feitas normalizações (batch normalization) após cada camada convolucional e densa, e também dropout pra cada camada densa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversão de WAV para MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método para conversão de arquivos de áudio WAV para Mel-Frequency Cepstrum Coefficient (MFCC), que é uma representação do espectro de potência de um som.\n",
    "\n",
    "O MFCC é utilizado para entrada das redes neurais do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2mfcc(file_path, max_pad_len=20):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=8000)\n",
    "    pad_width = max_pad_len - mfcc.shape[1]\n",
    "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_preds(model, X, y):\n",
    "    predictions = model.predict_classes(X)\n",
    "\n",
    "    print(classification_report(y, to_categorical(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para visualizar gráficos do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_val_graph(history):\n",
    "  #  \"Accuracy\"\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'validation'], loc='upper left')\n",
    "  plt.show()\n",
    "  # \"Loss\"\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'validation'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para plotar a matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, X_test, y_test, label):\n",
    "  y_pred = model.predict_classes(X_test)\n",
    "\n",
    "  cm = confusion_matrix(y_test.argmax(axis=1), y_pred)\n",
    "\n",
    "  df_cm = pd.DataFrame(cm, index = label,\n",
    "                    columns = label)\n",
    "  plt.figure(figsize = (10,7))\n",
    "  ax = sn.heatmap(df_cm, annot=True)\n",
    "  ax.set_title('Confusion matrix')\n",
    "  ax.set_ylabel(\"Label verdadeiro\")\n",
    "  ax.set_xlabel(\"Label predito\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproduzir o experimento de treinamento/classificação de dígitos do código github mencionado acima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando dados - Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados são carregados e convertidos para MFCC, além de armazenar o label do áudio através do nome do arquivo. (ex: **0**_nicolas_1.wav - nicolas falando o digito 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_digit(recording_path):\n",
    "    labels = []\n",
    "    mfccs = []\n",
    "\n",
    "    for f in os.listdir(recording_path):\n",
    "        if f.endswith('.wav'):\n",
    "            # MFCC\n",
    "            mfccs.append(wav2mfcc(recording_path + f))\n",
    "\n",
    "            # List of labels\n",
    "            label = f.split('_')[0]\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.asarray(mfccs), to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adquire os dados, o modelo, e faz a separação em dados de treinamento e teste (90% treinamento e 10% teste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(recording_path):\n",
    "    mfccs, labels = get_data_digit(recording_path)\n",
    "\n",
    "    dim_1 = mfccs.shape[1]\n",
    "    dim_2 = mfccs.shape[2]\n",
    "    channels = 1\n",
    "    classes = 10\n",
    "\n",
    "    X = mfccs\n",
    "    X = X.reshape((mfccs.shape[0], dim_1, dim_2, channels))\n",
    "    y = labels\n",
    "\n",
    "    input_shape = (dim_1, dim_2, channels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "    model = get_cnn_model(input_shape, classes)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
